# GitHub Actions Agent Evaluation for AgentEngine
# Triggers after staging deployment on main branch

name: Agent Evaluation

on:
  workflow_run:
    workflows: ["Deploy Staging"]
    types:
      - completed
    branches:
      - main

defaults:
  run:
    working-directory: AgentEngine

env:
  PYTHON_VERSION: '3.11'
  EVALUATION_THRESHOLD: '0.85'

jobs:
  evaluation:
    name: Run Agent Evaluation
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}

    permissions:
      contents: read
      id-token: write  # Required for Workload Identity Federation

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            AgentEngine/.venv
          key: uv-${{ runner.os }}-${{ hashFiles('AgentEngine/pyproject.toml', 'AgentEngine/uv.lock') }}
          restore-keys: |
            uv-${{ runner.os }}-

      - name: Install dependencies
        run: |
          uv venv .venv
          source .venv/bin/activate
          uv pip install -e ".[dev]"

      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Run Agent Evaluation
        id: evaluation
        run: |
          source .venv/bin/activate
          echo "=== Running agent evaluation ==="
          python scripts/evaluation/run_evaluation.py \
            --threshold ${{ env.EVALUATION_THRESHOLD }} \
            --output-json evaluation_results.json \
            --output-md evaluation_report.md
        env:
          GOOGLE_CLOUD_PROJECT: ${{ secrets.GCP_PROJECT_ID }}

      - name: Upload Evaluation Results
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-results
          path: |
            AgentEngine/evaluation_results.json
            AgentEngine/evaluation_report.md
          retention-days: 90
        if: always()

      - name: Check Evaluation Threshold
        run: |
          source .venv/bin/activate
          if [ -f evaluation_results.json ]; then
            SCORE=$(python -c "import json; print(json.load(open('evaluation_results.json'))['overall_score'])")
            echo "Evaluation Score: $SCORE"
            if (( $(echo "$SCORE < ${{ env.EVALUATION_THRESHOLD }}" | bc -l) )); then
              echo "::error::Evaluation score ($SCORE) is below threshold (${{ env.EVALUATION_THRESHOLD }})"
              exit 1
            fi
            echo "::notice::Evaluation passed with score: $SCORE"
          else
            echo "::warning::Evaluation results file not found"
          fi
        if: always()

      - name: Post Evaluation Summary
        run: |
          if [ -f evaluation_report.md ]; then
            echo "## Agent Evaluation Summary" >> $GITHUB_STEP_SUMMARY
            cat evaluation_report.md >> $GITHUB_STEP_SUMMARY
          fi
        if: always()
